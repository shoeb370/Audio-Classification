{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "optuna_final_v2.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shoeb370/Audio-Classification/blob/main/optuna_final_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "id": "7vDO7XIwrUsw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly_files = sorted(glob(r'/content/drive/MyDrive/jayesh_work/Dissertation/polysonmography_new/mesa-sleep-*.csv')) #Need to change /content/drive/MyDrive/jayesh_work/Dissertation/polysonmography_new\n",
        "poly_files\n",
        "# /content/drive/MyDrive/jayesh_work/Dissertation/mesa_new"
      ],
      "metadata": {
        "id": "h9l6OXT-ruim"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act_files = sorted(glob(r'/content/drive/MyDrive/jayesh_work/Dissertation/mesa_new/mesa-sleep-*.csv')) #Need to change /content/drive/MyDrive/jayesh_work/Dissertation/mesa_new\n",
        "act_files"
      ],
      "metadata": {
        "id": "DDrCYmxNr6p7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly_df = pd.DataFrame({\"poly_filename\":poly_files})\n",
        "poly_df.head()"
      ],
      "metadata": {
        "id": "cLrM9AYzuthN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly_df.poly_filename.iloc[0]\n"
      ],
      "metadata": {
        "id": "XRsCzykpuw_1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_files = [itm[0] for itm in poly_df.poly_filename.str.findall(r\"(?<=polysonmography_new/)(.*?)(?=-rpoint)\") if len(itm)>0]\n",
        "# new_files"
      ],
      "metadata": {
        "id": "17zc_KoKu02y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly_df[\"match_filename\"]= new_files\n",
        "poly_df.shape"
      ],
      "metadata": {
        "id": "zl1jAWutu0Tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "poly_df.head()"
      ],
      "metadata": {
        "id": "z2n2s-SauzbA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act_df = pd.DataFrame({\"act_filename\":act_files})\n",
        "# act_df\n",
        "# act_files[0]"
      ],
      "metadata": {
        "id": "9i_hNr7fwD8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act_new_files = [itm[0] for itm in act_df.act_filename.str.findall(r\"(?<=mesa_new/)(.*?)(?=.csv)\") if len(itm)>0]\n",
        "# act_new_files\n",
        "# act_new_files[0]"
      ],
      "metadata": {
        "id": "7pD_soUjwDJx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "act_df[\"match_filename\"]= act_new_files\n",
        "# act_df.shape\n",
        "# act_df.head()\n"
      ],
      "metadata": {
        "id": "sN0SKNS-wkXJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_final_df = poly_df.merge(act_df, how='inner')\n",
        "# temp_final_df.shape\n",
        "# temp_final_df.head()"
      ],
      "metadata": {
        "id": "0KpYE4FBxdQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_final_df.poly_filename.iloc[3]"
      ],
      "metadata": {
        "id": "rMhsEWJpyER3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = pd.DataFrame()\n",
        "Y = pd.DataFrame()\n",
        "\n",
        "# for i in range(5):\n",
        "for i in range(len(temp_final_df)):\n",
        "    \n",
        "    temp_df1_act = pd.read_csv(temp_final_df.act_filename.iloc[i])\n",
        "    temp_df1_poly = pd.read_csv(temp_final_df.poly_filename.iloc[i])\n",
        "    temp_df1_poly[\"stage\"] = temp_df1_poly[\"stage\"].fillna(0)\n",
        "    df1_truncated= temp_df1_act.tail(len(temp_df1_poly))\n",
        "    # df1_truncated= df1_truncated[[\"offwrist\", \"activity\",\"whitelight\",\"redlight\",\"greenlight\",\"bluelight\"]].fillna(0)\n",
        "    df1_truncated= df1_truncated[[\"offwrist\", \"activity\"]].fillna(0)\n",
        "    # X = X.append(df1_truncated[[\"offwrist\", \"activity\",\"whitelight\",\"redlight\",\"greenlight\",\"bluelight\"]])\n",
        "    X = X.append(df1_truncated[[\"offwrist\", \"activity\"]])\n",
        "    Y = Y.append(temp_df1_poly[[\"stage\"]])\n"
      ],
      "metadata": {
        "id": "XNpAJn5OyXH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, Y.shape"
      ],
      "metadata": {
        "id": "P7ztueNfyb7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xV6KT3riSN-e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# X = X[[\"offwrist\", \"activity\"]] #To comment to get all redlight, whitelight\n",
        "X['activity'] = X['activity'].astype(np.float64)\n",
        "X['offwrist'] = X['offwrist'].astype(np.float64)\n",
        "Y['stage'] = Y['stage'].astype(np.float64)\n",
        "\n",
        "X.activity.dtypes, X.offwrist.dtypes, Y.stage.dtypes"
      ],
      "metadata": {
        "id": "HRc5SSg21mtk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Y2 = Y['stage'].apply(lambda x: 0.0 if x == 0.0 else 1.0)"
      ],
      "metadata": {
        "id": "xKSrXflR2Ra6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X2 = X\n",
        "# X2 = X.head(5000) #to increase the length of the data\n",
        "# Y2 = Y2.head(5000) #to increase the length of the data"
      ],
      "metadata": {
        "id": "s0DGzmsrOVPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MjC_XailcXw0"
      },
      "outputs": [],
      "source": [
        "!pip install optuna"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import optuna\n",
        "\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "import xgboost as xgb"
      ],
      "metadata": {
        "id": "Wur1XohLcpje"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "akFLCDladwAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "metadata": {
        "id": "o3SgckGoeEkG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "def objective(trial):\n",
        "      # iris = sklearn.datasets.load_iris()\n",
        "      n_estimators = trial.suggest_int('n_estimators', 200, 2000,10)\n",
        "      max_depth = int(trial.suggest_float('max_depth', 10, 100, log=True))\n",
        "      clf = sklearn.ensemble.RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth)\n",
        "      return sklearn.model_selection.cross_val_score(clf, X2, Y2,\n",
        "           n_jobs=-1, cv=3).mean()"
      ],
      "metadata": {
        "id": "TWaOTUGbeIYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "9DOkTLBjfinN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "hiDzWc312qK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=100)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ],
      "metadata": {
        "id": "EH4QJOuQ2yir"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"random forest best parameter: \",study.best_params)"
      ],
      "metadata": {
        "id": "ZVmvIX_s8n1h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rf_n_estimators = study.best_params['n_estimators']\n",
        "rf_max_depth = study.best_params['max_depth']"
      ],
      "metadata": {
        "id": "Fya0KQutPq86"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Build RF model\n",
        "rf_clf = RandomForestClassifier(n_estimators = rf_n_estimators, max_depth= rf_max_depth)\n",
        "rf_clf.fit(X2, Y2)\n",
        "rf_accuracy = rf_clf.score(X2, Y2)\n",
        "print(rf_accuracy)"
      ],
      "metadata": {
        "id": "Mfx8zNq9Prkf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model of the Random forest\n",
        "import numpy as np\n",
        "import pickle\n",
        "pickle.dump(rf_clf, open('rf_model.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "SRJk2kUgR32P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved model of RF\n",
        "#I have taken x2[78] data which output should be 0\n",
        "pickled_model = pickle.load(open('rf_model.pkl', 'rb'))\n",
        "print(f\"the model output is:{pickled_model.predict([[21,0]])} \\n\",\"-\"*50)\n",
        "\n"
      ],
      "metadata": {
        "id": "mecp6pJDUpIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#SVC Best parameter\n",
        "import optuna\n",
        "import sklearn.svm\n",
        "def objective_svc(trial):\n",
        "    c = trial.suggest_float('svc_c', 1e-10, 1e10, log=True)\n",
        "    ## suggest_float(name, low, high, *, step=None, log=False)\n",
        "    ## Suggest a value for the floating point parameter.\n",
        "    clf = sklearn.svm.SVC(C=c, gamma='auto')\n",
        "\n",
        "    return sklearn.model_selection.cross_val_score(\n",
        "        clf,X2,Y2, n_jobs=-1, cv=3).mean() # cv= cross validation = 3. precision,recall, f1 score"
      ],
      "metadata": {
        "id": "dMJ7hDlZ27CH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# study = optuna.create_study(direction='maximize')\n",
        "# study.optimize(objective_svc, n_trials=100)\n",
        "\n",
        "# trial = study.best_trial\n",
        "\n",
        "# print('Accuracy: {}'.format(trial.value))\n",
        "# print(\"Best hyperparameters: {}\".format(trial.params))"
      ],
      "metadata": {
        "id": "0lNxQlIwgeMh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print(\"SVC's  best parameter: \",study.best_params)\n",
        "# c_best = study.best_params['svc_c']"
      ],
      "metadata": {
        "id": "hmF1Eh_ehPjT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# #building SVM - classification model for best parameters\n",
        "# svm_clf = sklearn.svm.SVC(C=c_best, gamma='auto')\n",
        "# svm_clf.fit(X2,Y2)\n",
        "# svc_accuracy = svm_clf.score(X2,Y2)\n",
        "# print(svc_accuracy)\n"
      ],
      "metadata": {
        "id": "uwRh7U8Warn8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Saving svm model and predicting\n",
        "# import numpy as np\n",
        "# import pickle\n",
        "# pickle.dump(svm_clf, open('svm_clf_model.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "ovaQcc1DBx29"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # load the saved model of SVM - C\n",
        "# pickled_model = pickle.load(open('svm_clf_model.pkl', 'rb'))\n",
        "# print(f\"the model output is:{pickled_model.predict([[11,0]])} \\n\",\"-\"*50)\n"
      ],
      "metadata": {
        "id": "zop_lcqpCH48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#XGB OPTUNA\n",
        "import xgboost as xgb\n",
        "def objective_xgb(trial):\n",
        "    # (data, target) = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
        "    train_x, valid_x, train_y, valid_y = train_test_split(X2, Y2, test_size=0.25)\n",
        "    dtrain = xgb.DMatrix(train_x, label=train_y)\n",
        "    dvalid = xgb.DMatrix(valid_x, label=valid_y)\n",
        "\n",
        "    param = {\n",
        "        \"verbosity\": 0,\n",
        "        \"objective\": \"binary:logistic\",\n",
        "        # use exact for small dataset.\n",
        "        \"tree_method\": \"exact\",\n",
        "        # defines booster, gblinear for linear functions.\n",
        "        \"booster\": trial.suggest_categorical(\"booster\", [\"gbtree\", \"gblinear\", \"dart\"]),\n",
        "        # L2 regularization weight.\n",
        "        \"lambda\": trial.suggest_float(\"lambda\", 1e-8, 1.0, log=True),\n",
        "        # L1 regularization weight.\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 1e-8, 1.0, log=True),\n",
        "        # sampling ratio for training data.\n",
        "        \"subsample\": trial.suggest_float(\"subsample\", 0.2, 1.0),\n",
        "        # sampling according to each tree.\n",
        "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.2, 1.0),\n",
        "    }\n",
        "\n",
        "    if param[\"booster\"] in [\"gbtree\", \"dart\"]:\n",
        "        # maximum depth of the tree, signifies complexity of the tree.\n",
        "        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 3, 9, step=2)\n",
        "        # minimum child weight, larger the term more conservative the tree.\n",
        "        param[\"min_child_weight\"] = trial.suggest_int(\"min_child_weight\", 2, 10)\n",
        "        param[\"eta\"] = trial.suggest_float(\"eta\", 1e-8, 1.0, log=True)\n",
        "        # defines how selective algorithm is.\n",
        "        param[\"gamma\"] = trial.suggest_float(\"gamma\", 1e-8, 1.0, log=True)\n",
        "        param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n",
        "\n",
        "    if param[\"booster\"] == \"dart\":\n",
        "        param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n",
        "        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n",
        "        param[\"rate_drop\"] = trial.suggest_float(\"rate_drop\", 1e-8, 1.0, log=True)\n",
        "        param[\"skip_drop\"] = trial.suggest_float(\"skip_drop\", 1e-8, 1.0, log=True)\n",
        "\n",
        "    bst = xgb.train(param, dtrain)\n",
        "    preds = bst.predict(dvalid)\n",
        "    pred_labels = np.rint(preds)\n",
        "    accuracy = sklearn.metrics.accuracy_score(valid_y, pred_labels)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "eUKJLshehvLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    study = optuna.create_study(direction=\"maximize\")\n",
        "    study.optimize(objective_xgb, n_trials=100, timeout=600)\n",
        "\n",
        "    print(\"Number of finished trials: \", len(study.trials))\n",
        "    print(\"Best trial:\")\n",
        "    trial = study.best_trial\n",
        "\n",
        "    print(\"  Value: {}\".format(trial.value))\n",
        "    print(\"  Params: \")\n",
        "    for key, value in trial.params.items():\n",
        "\n",
        "        print(\"    {}: {}\".format(key, value))"
      ],
      "metadata": {
        "id": "za7sTKwBicko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"XGB  best parameter: \",study.best_params)\n"
      ],
      "metadata": {
        "id": "t20k4XX6ixyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# XGBClassifier\n",
        "xgb_clf = xgb.XGBClassifier(params = study.best_params )\n",
        "xgb_clf.fit(X2,Y2)\n",
        "xgb_accuracy = xgb_clf.score(X2,Y2)\n",
        "print(xgb_accuracy)"
      ],
      "metadata": {
        "id": "OIuXgTPVHL_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Wr8uM_rQMiN5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model of XGB\n",
        "import numpy as np\n",
        "import pickle\n",
        "pickle.dump(xgb_clf, open('xgb_clf_model.pkl', 'wb'))"
      ],
      "metadata": {
        "id": "lyHSOB9dIsqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "offwrist_data = eval(input(\"Enter the offwrist value:\"))\n",
        "activity_data = eval(input(\"Enter the activity value:\"))\n",
        "list_off = [offwrist_data]; list_act = [activity_data]\n",
        "x_test_xgb = pd.DataFrame({\"offwrist\":[offwrist_data],\"activity\":[activity_data]})\n",
        "x_test_xgb[:1]\n",
        "xgb_clf.predict(x_test_xgb)"
      ],
      "metadata": {
        "id": "CbNUqgfDPQIA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved model of XGB -Clf\n",
        "pickled_model = pickle.load(open('xgb_clf_model.pkl', 'rb'))\n",
        "print(f\"the model output is:{pickled_model.predict(x_test_xgb)} \\n\",\"-\"*50)\n"
      ],
      "metadata": {
        "id": "xnsU3WvjMMUs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# rf_accuracy, svc_accuracy, xgb_accuracy"
      ],
      "metadata": {
        "id": "ojs5eLptMVg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  y_plot = [x for x in range(0.0,1.1,0.1)]"
      ],
      "metadata": {
        "id": "rq3LtkASfBP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "cdctg0Am98dS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "def objective_dt(trial):\n",
        "  # max_depth = trial.suggest_int('max_depth', 2, 100 ) #X2.shape[1]\n",
        "  max_depth = int(trial.suggest_float('max_depth', 10, 100, log=True))\n",
        "  min_samples_split = trial.suggest_int('min_samples_split', 2, 1000)\n",
        "  min_samples_leaf = trial.suggest_int('min_samples_leaf', 2, 1000)\n",
        "  max_features = trial.suggest_categorical(\"max_features\", [\"auto\",\"log2\",\"sqrt\",None])\n",
        "  clf = DecisionTreeClassifier(max_depth = max_depth, min_samples_split = min_samples_split,min_samples_leaf = min_samples_leaf,max_features = max_features)\n",
        "  \n",
        "  return sklearn.model_selection.cross_val_score(clf, X2, Y2,\n",
        "           n_jobs=-1, cv=3).mean()"
      ],
      "metadata": {
        "id": "fNg04R-Q-EWg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective_dt, n_trials=100)\n",
        "\n",
        "trial = study.best_trial\n",
        "\n",
        "print('Accuracy: {}'.format(trial.value))\n",
        "print(\"Best hyperparameters: {}\".format(trial.params))"
      ],
      "metadata": {
        "id": "Rud79POvAki6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Decision Tree's  best parameter: \",study.best_params)\n"
      ],
      "metadata": {
        "id": "VxffSy86_jK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "i6F3uvEJAnwZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf = DecisionTreeClassifier(max_depth = study.best_params['max_depth'],\n",
        "                             min_samples_split = study.best_params['min_samples_split'],\n",
        "                             min_samples_leaf = study.best_params['min_samples_leaf'],\n",
        "                             max_features = study.best_params['max_features'])"
      ],
      "metadata": {
        "id": "lK1PnHurBIPs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf.fit(X2,Y2)"
      ],
      "metadata": {
        "id": "vt0ps6QRGw0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dt_clf.score(X2,Y2)"
      ],
      "metadata": {
        "id": "NEy4gcHMImEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Save the model\n",
        "\n",
        "# Saving Decision Tree  model and predicting\n",
        "import numpy as np\n",
        "import pickle\n",
        "pickle.dump(dt_clf, open('dt_clf_model.pkl', 'wb'))\n"
      ],
      "metadata": {
        "id": "5Ap5Rc0QIrLw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the saved model of Decision Tree classifier model\n",
        "pickled_model = pickle.load(open('dt_clf_model.pkl', 'rb'))\n",
        "print(f\"the model output is:{pickled_model.predict([[11,0]])} \\n\",\"-\"*50)\n"
      ],
      "metadata": {
        "id": "Vbn-XiPWJReV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "zMbcIqzCJbN-"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}